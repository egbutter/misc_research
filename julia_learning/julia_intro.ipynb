{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Pkg\n",
    "using Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dict{String,Union{Nothing, VersionNumber}} with 2 entries:\n",
       "  \"HDF5\"   => v\"0.12.5\"\n",
       "  \"IJulia\" => v\"1.20.2\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Pkg.installed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32m\u001b[1mTest Passed\u001b[22m\u001b[39m"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@test 1==1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello World!\n"
     ]
    }
   ],
   "source": [
    "println(\"Hello World!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "3+3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"hello\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s1 = \"hello\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'h': ASCII/Unicode U+0068 (category Ll: Letter, lowercase)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s1[1]    # Julia is 1-indexed!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"Jonathan\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello Jonathan.\n"
     ]
    }
   ],
   "source": [
    "println(\"Hello $name.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"hello Jonathan\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s1 * \" \" * name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "MethodError",
     "evalue": "MethodError: no method matching Dict(::getfield(Main, Symbol(\"##3#5\")), ::getfield(Main, Symbol(\"##4#6\")))\nClosest candidates are:\n  Dict(::Any) at dict.jl:127",
     "output_type": "error",
     "traceback": [
      "MethodError: no method matching Dict(::getfield(Main, Symbol(\"##3#5\")), ::getfield(Main, Symbol(\"##4#6\")))\nClosest candidates are:\n  Dict(::Any) at dict.jl:127",
      "",
      "Stacktrace:",
      " [1] top-level scope at In[12]:1"
     ]
    }
   ],
   "source": [
    "my_phonebook = Dict(Jenny->\"867-5309\", Ghostbusters->\"2222\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Printf\n",
    "using Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "changeNum (generic function with 1 method)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function changeNum()\n",
    "    x::Int8 = 10\n",
    "    x = \"Dog\"\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10×10 Array{Int32,2}:\n",
       " 0  0  0  0  0  0  0  0  0  0\n",
       " 0  0  0  0  0  0  0  0  0  0\n",
       " 0  0  0  0  0  0  0  0  0  0\n",
       " 0  0  0  0  0  0  0  0  0  0\n",
       " 0  0  0  0  0  0  0  0  0  0\n",
       " 0  0  0  0  0  0  0  0  0  0\n",
       " 0  0  0  0  0  0  0  0  0  0\n",
       " 0  0  0  0  0  0  0  0  0  0\n",
       " 0  0  0  0  0  0  0  0  0  0\n",
       " 0  0  0  0  0  0  0  0  0  0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a1 = zeros(Int32, 10, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Distributed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nprocs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2-element Array{Int64,1}:\n",
       " 2\n",
       " 3"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "addprocs(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "for pid in workers()\n",
    "    println(pid)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Julia Iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Julia Version 1.2.0\n",
      "Commit c6da87ff4b (2019-08-20 00:03 UTC)\n",
      "Platform Info:\n",
      "  OS: Linux (x86_64-pc-linux-gnu)\n",
      "  CPU: Intel(R) Xeon(R) CPU E5-2666 v3 @ 2.90GHz\n",
      "  WORD_SIZE: 64\n",
      "  LIBM: libopenlibm\n",
      "  LLVM: libLLVM-6.0.1 (ORCJIT, haswell)\n",
      "Environment:\n",
      "  JULIA_DEPOT_PATH = /opt/julia\n",
      "  JULIA_VERSION = 1.2.0\n",
      "  JULIA_PKGDIR = /opt/julia\n"
     ]
    }
   ],
   "source": [
    "versioninfo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "true"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "JULIA_CUDA_SILENT = true   # Turn off notifications about GPU/CUDA; doesn't seem to work (?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m  Updating\u001b[22m\u001b[39m registry at `/opt/julia/registries/General`\n",
      "\u001b[32m\u001b[1m  Updating\u001b[22m\u001b[39m git-repo `https://github.com/JuliaRegistries/General.git`\n",
      "\u001b[2K\u001b[?25h[1mFetching:\u001b[22m\u001b[39m [========================================>]  99.9 %0.0 %\u001b[36m\u001b[1mFetching:\u001b[22m\u001b[39m [======>                                  ]  14.8 %>                             ]  26.8 %=============>                           ]  30.7 %]  42.7 %\u001b[36m\u001b[1mFetching:\u001b[22m\u001b[39m [=======================>                 ]  57.3 %>            ]  69.3 %>     ]  85.1 %\u001b[36m\u001b[1mFetching:\u001b[22m\u001b[39m [=======================================> ]  96.8 %\u001b[36m\u001b[1mFetching:\u001b[22m\u001b[39m [=======================================> ]  97.1 %\u001b[32m\u001b[1m Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m Installed\u001b[22m\u001b[39m ProgressMeter ────── v1.3.0\n",
      "\u001b[32m\u001b[1m Installed\u001b[22m\u001b[39m CMakeWrapper ─────── v0.2.4\n",
      "\u001b[32m\u001b[1m Installed\u001b[22m\u001b[39m Parsers ──────────── v1.0.5\n",
      "\u001b[32m\u001b[1m Installed\u001b[22m\u001b[39m CMake ────────────── v1.2.0\n",
      "\u001b[32m\u001b[1m Installed\u001b[22m\u001b[39m Blosc ────────────── v0.6.0\n",
      "\u001b[32m\u001b[1m Installed\u001b[22m\u001b[39m Parameters ───────── v0.12.1\n",
      "\u001b[32m\u001b[1m Installed\u001b[22m\u001b[39m ZMQ ──────────────── v1.1.0\n",
      "\u001b[32m\u001b[1m Installed\u001b[22m\u001b[39m BinaryProvider ───── v0.5.10\n",
      "\u001b[32m\u001b[1m Installed\u001b[22m\u001b[39m UnPack ───────────── v1.0.1\n",
      "\u001b[32m\u001b[1m Installed\u001b[22m\u001b[39m URIParser ────────── v0.4.1\n",
      "\u001b[32m\u001b[1m Installed\u001b[22m\u001b[39m OrderedCollections ─ v1.2.0\n",
      "\u001b[32m\u001b[1m Installed\u001b[22m\u001b[39m BinDeps ──────────── v1.0.1\n",
      "\u001b[32m\u001b[1m Installed\u001b[22m\u001b[39m VersionParsing ───── v1.2.0\n",
      "\u001b[32m\u001b[1m Installed\u001b[22m\u001b[39m Conda ────────────── v1.4.1\n",
      "\u001b[32m\u001b[1m  Updating\u001b[22m\u001b[39m `/opt/julia/environments/v1.2/Project.toml`\n",
      " \u001b[90m [92933f4c]\u001b[39m\u001b[92m + ProgressMeter v1.3.0\u001b[39m\n",
      "\u001b[32m\u001b[1m  Updating\u001b[22m\u001b[39m `/opt/julia/environments/v1.2/Manifest.toml`\n",
      " \u001b[90m [9e28174c]\u001b[39m\u001b[93m ↑ BinDeps v0.8.10 ⇒ v1.0.1\u001b[39m\n",
      " \u001b[90m [b99e7846]\u001b[39m\u001b[93m ↑ BinaryProvider v0.5.8 ⇒ v0.5.10\u001b[39m\n",
      " \u001b[90m [a74b3585]\u001b[39m\u001b[93m ↑ Blosc v0.5.1 ⇒ v0.6.0\u001b[39m\n",
      " \u001b[90m [631607c0]\u001b[39m\u001b[93m ↑ CMake v1.1.2 ⇒ v1.2.0\u001b[39m\n",
      " \u001b[90m [d5fb7624]\u001b[39m\u001b[93m ↑ CMakeWrapper v0.2.3 ⇒ v0.2.4\u001b[39m\n",
      " \u001b[90m [34da2185]\u001b[39m\u001b[91m - Compat v2.2.0\u001b[39m\n",
      " \u001b[90m [8f4d0f93]\u001b[39m\u001b[93m ↑ Conda v1.3.0 ⇒ v1.4.1\u001b[39m\n",
      " \u001b[90m [bac558e1]\u001b[39m\u001b[93m ↑ OrderedCollections v1.1.0 ⇒ v1.2.0\u001b[39m\n",
      " \u001b[90m [d96e819e]\u001b[39m\u001b[93m ↑ Parameters v0.12.0 ⇒ v0.12.1\u001b[39m\n",
      " \u001b[90m [69de0a69]\u001b[39m\u001b[93m ↑ Parsers v0.3.10 ⇒ v1.0.5\u001b[39m\n",
      " \u001b[90m [92933f4c]\u001b[39m\u001b[92m + ProgressMeter v1.3.0\u001b[39m\n",
      " \u001b[90m [30578b45]\u001b[39m\u001b[93m ↑ URIParser v0.4.0 ⇒ v0.4.1\u001b[39m\n",
      " \u001b[90m [3a884ed6]\u001b[39m\u001b[92m + UnPack v1.0.1\u001b[39m\n",
      " \u001b[90m [81def892]\u001b[39m\u001b[93m ↑ VersionParsing v1.1.3 ⇒ v1.2.0\u001b[39m\n",
      " \u001b[90m [c2297ded]\u001b[39m\u001b[93m ↑ ZMQ v1.0.0 ⇒ v1.1.0\u001b[39m\n",
      " \u001b[90m [8bb1440f]\u001b[39m\u001b[91m - DelimitedFiles \u001b[39m\n",
      " \u001b[90m [37e2e46d]\u001b[39m\u001b[91m - LinearAlgebra \u001b[39m\n",
      " \u001b[90m [1a1011a3]\u001b[39m\u001b[91m - SharedArrays \u001b[39m\n",
      " \u001b[90m [2f01184e]\u001b[39m\u001b[91m - SparseArrays \u001b[39m\n",
      " \u001b[90m [10745b16]\u001b[39m\u001b[91m - Statistics \u001b[39m\n",
      "\u001b[32m\u001b[1m  Building\u001b[22m\u001b[39m ZMQ ──→ `/opt/julia/packages/ZMQ/ItfqT/deps/build.log`\n",
      "\u001b[32m\u001b[1m  Building\u001b[22m\u001b[39m CMake → `/opt/julia/packages/CMake/ULbyn/deps/build.log`\n"
     ]
    }
   ],
   "source": [
    "using Pkg\n",
    "Pkg.add(\"ProgressMeter\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Flux\n",
    "using Flux: crossentropy, normalise, onecold, onehotbatch\n",
    "using ProgressMeter\n",
    "using Random\n",
    "using Statistics: mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pkgs = Pkg.installed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = Flux.Data.Iris.labels()\n",
    "features = Flux.Data.Iris.features();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# note features is features x samples (opposite of usual)\n",
    "\n",
    "labels[1:5], features[:, 1:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Subract mean, divide by std dev for normed mean of 0 and std dev of 1.\n",
    "normed_features = normalise(features, dims=2)   # 2 means rowwise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "?onehotbatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "klasses = sort(unique(labels))\n",
    "onehot_labels = onehotbatch(labels, klasses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "UndefVarError",
     "evalue": "UndefVarError: klasses not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: klasses not defined",
      "",
      "Stacktrace:",
      " [1] top-level scope at In[30]:1"
     ]
    }
   ],
   "source": [
    "klasses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "UndefVarError",
     "evalue": "UndefVarError: onehot_labels not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: onehot_labels not defined",
      "",
      "Stacktrace:",
      " [1] top-level scope at In[31]:1"
     ]
    }
   ],
   "source": [
    "onehot_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into training and test sets, 2/3 for training, 1/3 for test.\n",
    "# start:step:end and the ; means to concatenate the two\n",
    "# train_indices = [1:3:150 ; 2:3:150];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "UndefVarError",
     "evalue": "UndefVarError: labels not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: labels not defined",
      "",
      "Stacktrace:",
      " [1] top-level scope at In[33]:1"
     ]
    }
   ],
   "source": [
    "# this is more like the sklearn way\n",
    "idxs = randperm(length(labels))\n",
    "train_cut = Int(length(labels) * 0.66)\n",
    "train_indices = idxs[1:train_cut]\n",
    "test_indices = idxs[train_cut:length(labels)];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "UndefVarError",
     "evalue": "UndefVarError: normed_features not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: normed_features not defined",
      "",
      "Stacktrace:",
      " [1] top-level scope at In[34]:1"
     ]
    }
   ],
   "source": [
    "X_train = normed_features[:, train_indices]\n",
    "y_train = onehot_labels[:, train_indices]\n",
    "\n",
    "X_test = normed_features[:, test_indices]\n",
    "y_test = onehot_labels[:, test_indices];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "search: \u001b[0m\u001b[1mc\u001b[22m\u001b[0m\u001b[1mh\u001b[22m\u001b[0m\u001b[1ma\u001b[22mnnel_from_\u001b[0m\u001b[1mi\u001b[22md\n",
      "\n",
      "Couldn't find \u001b[36mChain\u001b[39m\n",
      "Perhaps you meant Char, Main, Channel, Cchar, chown, Cint, Colon, Cuint or Cvoid\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "No documentation found.\n",
       "\n",
       "Binding \\texttt{Chain} does not exist.\n",
       "\n"
      ],
      "text/markdown": [
       "No documentation found.\n",
       "\n",
       "Binding `Chain` does not exist.\n"
      ],
      "text/plain": [
       "  No documentation found.\n",
       "\n",
       "  Binding \u001b[36mChain\u001b[39m does not exist."
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "?Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "search: \u001b[0m\u001b[1mD\u001b[22m\u001b[0m\u001b[1me\u001b[22m\u001b[0m\u001b[1mn\u001b[22m\u001b[0m\u001b[1ms\u001b[22m\u001b[0m\u001b[1me\u001b[22m \u001b[0m\u001b[1mD\u001b[22m\u001b[0m\u001b[1me\u001b[22m\u001b[0m\u001b[1mn\u001b[22m\u001b[0m\u001b[1ms\u001b[22m\u001b[0m\u001b[1me\u001b[22mArray \u001b[0m\u001b[1mD\u001b[22m\u001b[0m\u001b[1me\u001b[22m\u001b[0m\u001b[1mn\u001b[22m\u001b[0m\u001b[1ms\u001b[22m\u001b[0m\u001b[1me\u001b[22mVector \u001b[0m\u001b[1mD\u001b[22m\u001b[0m\u001b[1me\u001b[22m\u001b[0m\u001b[1mn\u001b[22m\u001b[0m\u001b[1ms\u001b[22m\u001b[0m\u001b[1me\u001b[22mMatrix \u001b[0m\u001b[1mD\u001b[22m\u001b[0m\u001b[1me\u001b[22m\u001b[0m\u001b[1mn\u001b[22m\u001b[0m\u001b[1ms\u001b[22m\u001b[0m\u001b[1me\u001b[22mVecOrMat \u001b[0m\u001b[1mD\u001b[22m\u001b[0m\u001b[1me\u001b[22m\u001b[0m\u001b[1mn\u001b[22m\u001b[0m\u001b[1ms\u001b[22m\u001b[0m\u001b[1me\u001b[22mConvDims\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "\\begin{verbatim}\n",
       "Dense(in::Integer, out::Integer, σ = identity)\n",
       "\\end{verbatim}\n",
       "Creates a traditional \\texttt{Dense} layer with parameters \\texttt{W} and \\texttt{b}.\n",
       "\n",
       "\\begin{verbatim}\n",
       "y = σ.(W * x .+ b)\n",
       "\\end{verbatim}\n",
       "The input \\texttt{x} must be a vector of length \\texttt{in}, or a batch of vectors represented as an \\texttt{in × N} matrix. The out \\texttt{y} will be a vector or batch of length \\texttt{out}.\n",
       "\n",
       "\\begin{verbatim}\n",
       "julia> d = Dense(5, 2)\n",
       "Dense(5, 2)\n",
       "\n",
       "julia> d(rand(5))\n",
       "Tracked 2-element Array{Float64,1}:\n",
       "  0.00257447\n",
       "  -0.00449443\n",
       "\\end{verbatim}\n"
      ],
      "text/markdown": [
       "```\n",
       "Dense(in::Integer, out::Integer, σ = identity)\n",
       "```\n",
       "\n",
       "Creates a traditional `Dense` layer with parameters `W` and `b`.\n",
       "\n",
       "```\n",
       "y = σ.(W * x .+ b)\n",
       "```\n",
       "\n",
       "The input `x` must be a vector of length `in`, or a batch of vectors represented as an `in × N` matrix. The out `y` will be a vector or batch of length `out`.\n",
       "\n",
       "```julia\n",
       "julia> d = Dense(5, 2)\n",
       "Dense(5, 2)\n",
       "\n",
       "julia> d(rand(5))\n",
       "Tracked 2-element Array{Float64,1}:\n",
       "  0.00257447\n",
       "  -0.00449443\n",
       "```\n"
      ],
      "text/plain": [
       "\u001b[36m  Dense(in::Integer, out::Integer, σ = identity)\u001b[39m\n",
       "\n",
       "  Creates a traditional \u001b[36mDense\u001b[39m layer with parameters \u001b[36mW\u001b[39m and \u001b[36mb\u001b[39m.\n",
       "\n",
       "\u001b[36m  y = σ.(W * x .+ b)\u001b[39m\n",
       "\n",
       "  The input \u001b[36mx\u001b[39m must be a vector of length \u001b[36min\u001b[39m, or a batch of vectors represented\n",
       "  as an \u001b[36min × N\u001b[39m matrix. The out \u001b[36my\u001b[39m will be a vector or batch of length \u001b[36mout\u001b[39m.\n",
       "\n",
       "\u001b[36m  julia> d = Dense(5, 2)\u001b[39m\n",
       "\u001b[36m  Dense(5, 2)\u001b[39m\n",
       "\u001b[36m  \u001b[39m\n",
       "\u001b[36m  julia> d(rand(5))\u001b[39m\n",
       "\u001b[36m  Tracked 2-element Array{Float64,1}:\u001b[39m\n",
       "\u001b[36m    0.00257447\u001b[39m\n",
       "\u001b[36m    -0.00449443\u001b[39m"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "?Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3×4 Array{Float32,2}:\n",
       "  0.775586  -0.304971   0.421589   -0.436464\n",
       " -0.323282  -0.164366   0.0802988  -0.390513\n",
       "  0.347033  -0.63944   -0.0454182  -0.369854"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The dense layer is just a matrix multiply; it has param W with shape (NxM); input is M, output is N\n",
    "# This is 4 inputs to three neurons; there is a bias which is an integer\n",
    "# Note the .+ to indicate broadcasting\n",
    "x = [5, 1, 4, 6]\n",
    "b = 0.25\n",
    "W = Dense(4,3).W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "search: \u001b[0m\u001b[1mi\u001b[22m\u001b[0m\u001b[1md\u001b[22m\u001b[0m\u001b[1me\u001b[22m\u001b[0m\u001b[1mn\u001b[22m\u001b[0m\u001b[1mt\u001b[22m\u001b[0m\u001b[1mi\u001b[22m\u001b[0m\u001b[1mt\u001b[22m\u001b[0m\u001b[1my\u001b[22m\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "\\begin{verbatim}\n",
       "identity(x)\n",
       "\\end{verbatim}\n",
       "The identity function. Returns its argument.\n",
       "\n",
       "\\section{Examples}\n",
       "\\begin{verbatim}\n",
       "julia> identity(\"Well, what did you expect?\")\n",
       "\"Well, what did you expect?\"\n",
       "\\end{verbatim}\n"
      ],
      "text/markdown": [
       "```\n",
       "identity(x)\n",
       "```\n",
       "\n",
       "The identity function. Returns its argument.\n",
       "\n",
       "# Examples\n",
       "\n",
       "```jldoctest\n",
       "julia> identity(\"Well, what did you expect?\")\n",
       "\"Well, what did you expect?\"\n",
       "```\n"
      ],
      "text/plain": [
       "\u001b[36m  identity(x)\u001b[39m\n",
       "\n",
       "  The identity function. Returns its argument.\n",
       "\n",
       "\u001b[1m  Examples\u001b[22m\n",
       "\u001b[1m  ≡≡≡≡≡≡≡≡≡≡\u001b[22m\n",
       "\n",
       "\u001b[36m  julia> identity(\"Well, what did you expect?\")\u001b[39m\n",
       "\u001b[36m  \"Well, what did you expect?\"\u001b[39m"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "?identity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3-element Array{Float64,1}:\n",
       " 4.041679382324219 \n",
       " 0.5067691802978516\n",
       " 8.800432205200195 "
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W*x .+ b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Chain(Dense(4, 3), softmax)"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Declare model taking 4 features as inputs and outputting 3 probabiltiies, \n",
    "# one for each species of iris.\n",
    "model = Chain(\n",
    "    Dense(4, 3),\n",
    "    softmax\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Dense(4, 3), NNlib.softmax)"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Params([Float32[-1.4777225 1.6287514 -2.0652995 -2.1090415; 0.5130562 -0.70725 -0.4703287 -0.9004947; 0.3975363 -0.8862645 2.6626518 2.6652656], Float32[-0.34812948, 2.2498853, -1.901755]])"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the parameters of the first layer\n",
    "params(model[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chain means a function that applies step wise functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "search: \u001b[0m\u001b[1ms\u001b[22m\u001b[0m\u001b[1mo\u001b[22m\u001b[0m\u001b[1mf\u001b[22m\u001b[0m\u001b[1mt\u001b[22m\u001b[0m\u001b[1mm\u001b[22m\u001b[0m\u001b[1ma\u001b[22m\u001b[0m\u001b[1mx\u001b[22m \u001b[0m\u001b[1ms\u001b[22m\u001b[0m\u001b[1mo\u001b[22m\u001b[0m\u001b[1mf\u001b[22m\u001b[0m\u001b[1mt\u001b[22m\u001b[0m\u001b[1mm\u001b[22m\u001b[0m\u001b[1ma\u001b[22m\u001b[0m\u001b[1mx\u001b[22m! ∇\u001b[0m\u001b[1ms\u001b[22m\u001b[0m\u001b[1mo\u001b[22m\u001b[0m\u001b[1mf\u001b[22m\u001b[0m\u001b[1mt\u001b[22m\u001b[0m\u001b[1mm\u001b[22m\u001b[0m\u001b[1ma\u001b[22m\u001b[0m\u001b[1mx\u001b[22m ∇\u001b[0m\u001b[1ms\u001b[22m\u001b[0m\u001b[1mo\u001b[22m\u001b[0m\u001b[1mf\u001b[22m\u001b[0m\u001b[1mt\u001b[22m\u001b[0m\u001b[1mm\u001b[22m\u001b[0m\u001b[1ma\u001b[22m\u001b[0m\u001b[1mx\u001b[22m! log\u001b[0m\u001b[1ms\u001b[22m\u001b[0m\u001b[1mo\u001b[22m\u001b[0m\u001b[1mf\u001b[22m\u001b[0m\u001b[1mt\u001b[22m\u001b[0m\u001b[1mm\u001b[22m\u001b[0m\u001b[1ma\u001b[22m\u001b[0m\u001b[1mx\u001b[22m log\u001b[0m\u001b[1ms\u001b[22m\u001b[0m\u001b[1mo\u001b[22m\u001b[0m\u001b[1mf\u001b[22m\u001b[0m\u001b[1mt\u001b[22m\u001b[0m\u001b[1mm\u001b[22m\u001b[0m\u001b[1ma\u001b[22m\u001b[0m\u001b[1mx\u001b[22m! ∇log\u001b[0m\u001b[1ms\u001b[22m\u001b[0m\u001b[1mo\u001b[22m\u001b[0m\u001b[1mf\u001b[22m\u001b[0m\u001b[1mt\u001b[22m\u001b[0m\u001b[1mm\u001b[22m\u001b[0m\u001b[1ma\u001b[22m\u001b[0m\u001b[1mx\u001b[22m\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "\\begin{verbatim}\n",
       "softmax(xs) = exp.(xs) ./ sum(exp.(xs))\n",
       "\\end{verbatim}\n",
       "\\href{https://en.wikipedia.org/wiki/Softmax_function}{Softmax} takes log-probabilities (any real vector) and returns a probability distribution that sums to 1.\n",
       "\n",
       "If given a matrix it will treat it as a batch of vectors, with each column independent.\n",
       "\n",
       "\\begin{verbatim}\n",
       "julia> softmax([1,2,3.])\n",
       "3-element Array{Float64,1}:\n",
       "  0.0900306\n",
       "  0.244728\n",
       "  0.665241\n",
       "\\end{verbatim}\n"
      ],
      "text/markdown": [
       "```\n",
       "softmax(xs) = exp.(xs) ./ sum(exp.(xs))\n",
       "```\n",
       "\n",
       "[Softmax](https://en.wikipedia.org/wiki/Softmax_function) takes log-probabilities (any real vector) and returns a probability distribution that sums to 1.\n",
       "\n",
       "If given a matrix it will treat it as a batch of vectors, with each column independent.\n",
       "\n",
       "```\n",
       "julia> softmax([1,2,3.])\n",
       "3-element Array{Float64,1}:\n",
       "  0.0900306\n",
       "  0.244728\n",
       "  0.665241\n",
       "```\n"
      ],
      "text/plain": [
       "\u001b[36m  softmax(xs) = exp.(xs) ./ sum(exp.(xs))\u001b[39m\n",
       "\n",
       "  Softmax (https://en.wikipedia.org/wiki/Softmax_function) takes\n",
       "  log-probabilities (any real vector) and returns a probability distribution\n",
       "  that sums to 1.\n",
       "\n",
       "  If given a matrix it will treat it as a batch of vectors, with each column\n",
       "  independent.\n",
       "\n",
       "\u001b[36m  julia> softmax([1,2,3.])\u001b[39m\n",
       "\u001b[36m  3-element Array{Float64,1}:\u001b[39m\n",
       "\u001b[36m    0.0900306\u001b[39m\n",
       "\u001b[36m    0.244728\u001b[39m\n",
       "\u001b[36m    0.665241\u001b[39m"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "?softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Descent(0.5)"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss(x, y) = crossentropy(model(x), y)\n",
    "\n",
    "# Gradient descent optimiser with learning rate 0.5.\n",
    "optimiser = Descent(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "search: \u001b[0m\u001b[1mD\u001b[22m\u001b[0m\u001b[1me\u001b[22m\u001b[0m\u001b[1ms\u001b[22m\u001b[0m\u001b[1mc\u001b[22m\u001b[0m\u001b[1me\u001b[22m\u001b[0m\u001b[1mn\u001b[22m\u001b[0m\u001b[1mt\u001b[22m\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "Descent(η)\n",
       "\n",
       "Classic gradient descent optimiser with learning rate \\texttt{η}. For each parameter \\texttt{p} and its gradient \\texttt{δp}, this runs \\texttt{p -= η*δp}\n",
       "\n",
       "\\subsection{Parameters}\n",
       "\\begin{itemize}\n",
       "\\item Learning Rate (η): The amount by which the gradients are discounted before updating the weights. Defaults to \\texttt{0.1}.\n",
       "\n",
       "\\end{itemize}\n",
       "\\subsection{Example}\n",
       "\\begin{verbatim}\n",
       "opt = Descent() # uses default η (0.1)\n",
       "\n",
       "opt = Descent(0.3) # use provided η\n",
       "\n",
       "ps = params(model)\n",
       "\n",
       "gs = gradient(ps) do\n",
       "  loss(x, y)\n",
       "end\n",
       "\n",
       "Flux.Optimise.update!(opt, ps, gs)\n",
       "\\end{verbatim}\n"
      ],
      "text/markdown": [
       "Descent(η)\n",
       "\n",
       "Classic gradient descent optimiser with learning rate `η`. For each parameter `p` and its gradient `δp`, this runs `p -= η*δp`\n",
       "\n",
       "## Parameters\n",
       "\n",
       "  * Learning Rate (η): The amount by which the gradients are discounted before updating the weights. Defaults to `0.1`.\n",
       "\n",
       "## Example\n",
       "\n",
       "```julia-repl\n",
       "opt = Descent() # uses default η (0.1)\n",
       "\n",
       "opt = Descent(0.3) # use provided η\n",
       "\n",
       "ps = params(model)\n",
       "\n",
       "gs = gradient(ps) do\n",
       "  loss(x, y)\n",
       "end\n",
       "\n",
       "Flux.Optimise.update!(opt, ps, gs)\n",
       "```\n"
      ],
      "text/plain": [
       "  Descent(η)\n",
       "\n",
       "  Classic gradient descent optimiser with learning rate \u001b[36mη\u001b[39m. For each parameter\n",
       "  \u001b[36mp\u001b[39m and its gradient \u001b[36mδp\u001b[39m, this runs \u001b[36mp -= η*δp\u001b[39m\n",
       "\n",
       "\u001b[1m  Parameters\u001b[22m\n",
       "\u001b[1m  ============\u001b[22m\n",
       "\n",
       "    •    Learning Rate (η): The amount by which the gradients are\n",
       "        discounted before updating the weights. Defaults to \u001b[36m0.1\u001b[39m.\n",
       "\n",
       "\u001b[1m  Example\u001b[22m\n",
       "\u001b[1m  =========\u001b[22m\n",
       "\n",
       "\u001b[36m  opt = Descent() # uses default η (0.1)\u001b[39m\n",
       "\u001b[36m  \u001b[39m\n",
       "\u001b[36m  opt = Descent(0.3) # use provided η\u001b[39m\n",
       "\u001b[36m  \u001b[39m\n",
       "\u001b[36m  ps = params(model)\u001b[39m\n",
       "\u001b[36m  \u001b[39m\n",
       "\u001b[36m  gs = gradient(ps) do\u001b[39m\n",
       "\u001b[36m    loss(x, y)\u001b[39m\n",
       "\u001b[36m  end\u001b[39m\n",
       "\u001b[36m  \u001b[39m\n",
       "\u001b[36m  Flux.Optimise.update!(opt, ps, gs)\u001b[39m"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "?Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Base.Iterators.Take{Base.Iterators.Repeated{Tuple{Array{Float64,2},Flux.OneHotMatrix{Array{Flux.OneHotVector,1}}}}}(Base.Iterators.Repeated{Tuple{Array{Float64,2},Flux.OneHotMatrix{Array{Flux.OneHotVector,1}}}}(([0.5533332750260047 -0.9006811702978109 … -0.05250607719225172 -0.5371775589668563; -1.281972426831577 1.0320572244889543 … -0.5877635314354182 0.800654259356901; 0.705892938853251 -1.3412724047598341 … 0.7627586428425032 -1.2844067007705817; 0.9220637630692059 -1.3129767272601456 … 1.579428613166074 -1.0500307872213983], Bool[0 1 … 0 1; 0 0 … 0 0; 1 0 … 1 0])), 150)"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create iterator to train model over 110 epochs.\n",
    "data_iterator = Iterators.repeated((X_train, y_train), 150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "\\begin{verbatim}\n",
       "repeated(x[, n::Int])\n",
       "\\end{verbatim}\n",
       "An iterator that generates the value \\texttt{x} forever. If \\texttt{n} is specified, generates \\texttt{x} that many times (equivalent to \\texttt{take(repeated(x), n)}).\n",
       "\n",
       "\\section{Examples}\n",
       "\\begin{verbatim}\n",
       "julia> a = Iterators.repeated([1 2], 4);\n",
       "\n",
       "julia> collect(a)\n",
       "4-element Array{Array{Int64,2},1}:\n",
       " [1 2]\n",
       " [1 2]\n",
       " [1 2]\n",
       " [1 2]\n",
       "\\end{verbatim}\n"
      ],
      "text/markdown": [
       "```\n",
       "repeated(x[, n::Int])\n",
       "```\n",
       "\n",
       "An iterator that generates the value `x` forever. If `n` is specified, generates `x` that many times (equivalent to `take(repeated(x), n)`).\n",
       "\n",
       "# Examples\n",
       "\n",
       "```jldoctest\n",
       "julia> a = Iterators.repeated([1 2], 4);\n",
       "\n",
       "julia> collect(a)\n",
       "4-element Array{Array{Int64,2},1}:\n",
       " [1 2]\n",
       " [1 2]\n",
       " [1 2]\n",
       " [1 2]\n",
       "```\n"
      ],
      "text/plain": [
       "\u001b[36m  repeated(x[, n::Int])\u001b[39m\n",
       "\n",
       "  An iterator that generates the value \u001b[36mx\u001b[39m forever. If \u001b[36mn\u001b[39m is specified, generates\n",
       "  \u001b[36mx\u001b[39m that many times (equivalent to \u001b[36mtake(repeated(x), n)\u001b[39m).\n",
       "\n",
       "\u001b[1m  Examples\u001b[22m\n",
       "\u001b[1m  ≡≡≡≡≡≡≡≡≡≡\u001b[22m\n",
       "\n",
       "\u001b[36m  julia> a = Iterators.repeated([1 2], 4);\u001b[39m\n",
       "\u001b[36m  \u001b[39m\n",
       "\u001b[36m  julia> collect(a)\u001b[39m\n",
       "\u001b[36m  4-element Array{Array{Int64,2},1}:\u001b[39m\n",
       "\u001b[36m   [1 2]\u001b[39m\n",
       "\u001b[36m   [1 2]\u001b[39m\n",
       "\u001b[36m   [1 2]\u001b[39m\n",
       "\u001b[36m   [1 2]\u001b[39m"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "?Iterators.repeated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "\\begin{verbatim}\n",
       "train!(loss, params, data, opt; cb)\n",
       "\\end{verbatim}\n",
       "For each datapoint \\texttt{d} in \\texttt{data} computes the gradient of \\texttt{loss(d...)} through backpropagation and calls the optimizer \\texttt{opt}.\n",
       "\n",
       "Takes a callback as keyword argument \\texttt{cb}. For example, this will print \"training\" every 10 seconds:\n",
       "\n",
       "\\begin{verbatim}\n",
       "Flux.train!(loss, params, data, opt,\n",
       "            cb = throttle(() -> println(\"training\"), 10))\n",
       "\\end{verbatim}\n",
       "The callback can call \\texttt{Flux.stop()} to interrupt the training loop.\n",
       "\n",
       "Multiple optimisers and callbacks can be passed to \\texttt{opt} and \\texttt{cb} as arrays.\n",
       "\n"
      ],
      "text/markdown": [
       "```\n",
       "train!(loss, params, data, opt; cb)\n",
       "```\n",
       "\n",
       "For each datapoint `d` in `data` computes the gradient of `loss(d...)` through backpropagation and calls the optimizer `opt`.\n",
       "\n",
       "Takes a callback as keyword argument `cb`. For example, this will print \"training\" every 10 seconds:\n",
       "\n",
       "```julia\n",
       "Flux.train!(loss, params, data, opt,\n",
       "            cb = throttle(() -> println(\"training\"), 10))\n",
       "```\n",
       "\n",
       "The callback can call `Flux.stop()` to interrupt the training loop.\n",
       "\n",
       "Multiple optimisers and callbacks can be passed to `opt` and `cb` as arrays.\n"
      ],
      "text/plain": [
       "\u001b[36m  train!(loss, params, data, opt; cb)\u001b[39m\n",
       "\n",
       "  For each datapoint \u001b[36md\u001b[39m in \u001b[36mdata\u001b[39m computes the gradient of \u001b[36mloss(d...)\u001b[39m through\n",
       "  backpropagation and calls the optimizer \u001b[36mopt\u001b[39m.\n",
       "\n",
       "  Takes a callback as keyword argument \u001b[36mcb\u001b[39m. For example, this will print\n",
       "  \"training\" every 10 seconds:\n",
       "\n",
       "\u001b[36m  Flux.train!(loss, params, data, opt,\u001b[39m\n",
       "\u001b[36m              cb = throttle(() -> println(\"training\"), 10))\u001b[39m\n",
       "\n",
       "  The callback can call \u001b[36mFlux.stop()\u001b[39m to interrupt the training loop.\n",
       "\n",
       "  Multiple optimisers and callbacks can be passed to \u001b[36mopt\u001b[39m and \u001b[36mcb\u001b[39m as arrays."
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "?Flux.train!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.026197 seconds (458.13 k allocations: 11.549 MiB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Training done...\n",
      "└ @ Main In[259]:2\n"
     ]
    }
   ],
   "source": [
    "@time Flux.train!(loss, params(model), data_iterator, optimiser)\n",
    "@info \"Training done...\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "search: SkipC\u001b[0m\u001b[1mo\u001b[22m\u001b[0m\u001b[1mn\u001b[22mn\u001b[0m\u001b[1me\u001b[22m\u001b[0m\u001b[1mc\u001b[22mti\u001b[0m\u001b[1mo\u001b[22mn Exp\u001b[0m\u001b[1mo\u001b[22m\u001b[0m\u001b[1mn\u001b[22m\u001b[0m\u001b[1me\u001b[22mntialBa\u001b[0m\u001b[1mc\u001b[22mk\u001b[0m\u001b[1mO\u001b[22mff\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "\\begin{verbatim}\n",
       "onecold(y[, labels = 1:length(y)])\n",
       "\\end{verbatim}\n",
       "Inverse operations of \\href{@ref}{\\texttt{onehot}}.\n",
       "\n",
       "\\begin{verbatim}\n",
       "julia> using Flux: onecold\n",
       "\n",
       "julia> onecold([true, false, false], [:a, :b, :c])\n",
       ":a\n",
       "\n",
       "julia> onecold([0.3, 0.2, 0.5], [:a, :b, :c])\n",
       ":c\n",
       "\\end{verbatim}\n"
      ],
      "text/markdown": [
       "```\n",
       "onecold(y[, labels = 1:length(y)])\n",
       "```\n",
       "\n",
       "Inverse operations of [`onehot`](@ref).\n",
       "\n",
       "```jldoctest\n",
       "julia> using Flux: onecold\n",
       "\n",
       "julia> onecold([true, false, false], [:a, :b, :c])\n",
       ":a\n",
       "\n",
       "julia> onecold([0.3, 0.2, 0.5], [:a, :b, :c])\n",
       ":c\n",
       "```\n"
      ],
      "text/plain": [
       "\u001b[36m  onecold(y[, labels = 1:length(y)])\u001b[39m\n",
       "\n",
       "  Inverse operations of \u001b[36monehot\u001b[39m.\n",
       "\n",
       "\u001b[36m  julia> using Flux: onecold\u001b[39m\n",
       "\u001b[36m  \u001b[39m\n",
       "\u001b[36m  julia> onecold([true, false, false], [:a, :b, :c])\u001b[39m\n",
       "\u001b[36m  :a\u001b[39m\n",
       "\u001b[36m  \u001b[39m\n",
       "\u001b[36m  julia> onecold([0.3, 0.2, 0.5], [:a, :b, :c])\u001b[39m\n",
       "\u001b[36m  :c\u001b[39m"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "?onecold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52-element Array{Int64,1}:\n",
       " 2\n",
       " 3\n",
       " 3\n",
       " 2\n",
       " 2\n",
       " 1\n",
       " 2\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 2\n",
       " ⋮\n",
       " 1\n",
       " 3\n",
       " 3\n",
       " 3\n",
       " 3\n",
       " 2\n",
       " 1\n",
       " 1\n",
       " 3\n",
       " 3\n",
       " 3\n",
       " 3"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#onecold is like argmax\n",
    "onecold(model(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3×52 Flux.OneHotMatrix{Array{Flux.OneHotVector,1}}:\n",
       " 0  0  0  0  0  1  0  1  1  1  1  1  0  …  1  0  0  0  0  0  1  1  0  0  0  0\n",
       " 1  0  0  1  0  0  1  0  0  0  0  0  1     0  0  0  0  0  1  0  0  0  0  0  0\n",
       " 0  1  1  0  1  0  0  0  0  0  0  0  0     0  1  1  1  1  0  0  0  1  1  1  1"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "accuracy (generic function with 1 method)"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate trained model against test set.\n",
    "accuracy(x, y) = mean(onecold(model(x)) .== onecold(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.005635 seconds (2.87 k allocations: 138.418 KiB)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9230769230769231"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@time accuracy_score = accuracy(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "confusion_matrix (generic function with 1 method)"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function confusion_matrix(X, y)\n",
    "    ŷ = onehotbatch(onecold(model(X)), 1:3)\n",
    "    y * ŷ'\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3×3 Array{Int64,2}:\n",
       " 16   0   0\n",
       "  0  15   2\n",
       "  0   2  17"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(confusion_matrix(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.2.0",
   "language": "julia",
   "name": "julia-1.2"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
